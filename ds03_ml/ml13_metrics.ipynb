{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26736789",
   "metadata": {},
   "source": [
    "metrics(평가지표)\n",
    "\n",
    "MAE(Mean Absolute Error): 오차 절대값 평균\n",
    "\n",
    "MSE(Mean Squared Error):오차 제곱 평균\n",
    "\n",
    "RMSE(Root Mean Squared Error) :  \"오차 제곱 평균\"의 제곱근\n",
    "\n",
    "R Squared(결정계수) : 예측값 Variance / 실제값 Variance(1에 가까울수록 정확도가 높다)\n",
    "\n",
    "confusion matrix(혼동 행렬)\n",
    "\n",
    "- TP (True Positive)   암을 암이라고 정확하게 예측\n",
    "- FP (False Positive)  암이 아닌것을 암이 아니라고 정확하게 예측\n",
    "- TN (True Negative)   암을 암이 아니라고 잘못 예측\n",
    "- FN (False Negative)  암이 아닌것을 암이라고 잘못 예측\n",
    "\n",
    "\n",
    "accuracy(score) : 정답 / 전체 -> (TP + TN) / (TP + TN + FP + FN)\n",
    "<!-- 내가 얼마나 정답이라고 예측했는가?  전체중에서 맞춘값 -->\n",
    "<!-- 정답인 T인 것들만 뽑아서 계산 -->\n",
    "\n",
    "정답을 전체로 나눈걸 스코어라고 이야기하고 있다.\n",
    "\n",
    "f1_score : Precision과 Recall의 조화평균\n",
    "<!-- 데이터가 불균형할 때 사용한다. -->\n",
    "<!-- 공식에서 A는 Precision  B=Recall -->\n",
    "<!-- 이 아래 내용을 보면 1종 오류와 2종 오류라는 이야기가 있는데, 거기에서 나온 내용이라 통계분석 공부를 해야한다. -->\n",
    "- 2 * (precision * recall / precision + recall)\n",
    "\n",
    "- Precision(정밀도) : TP/(TP + FP) (True로 분류한 것 중 정답 비율)  내가 예측한 분류가 맞아야하니까 뒤에가 무조건 P여야 한다.\n",
    "- Recall(재현율 / 민감도) : TP / (TP + FN) (실제 True 중 True로 예측한 비율)\n",
    "- TPR(True Positive Rate) : TP / (TP + FN) (= Recall)\n",
    "- FRP (False Positive Rate) : FP / (FP + TN) (실제 False 중 False로 예측한 비율/ FPR은 모델이 실제 Negative를 잘못하여 Positive로 잘못 예측하는 비율을 나타냅니다.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도(accuracy)는 전체 샘플 중 맞게 예측한 샘플 수의 비율을 뜻한다. 높을수록 좋은 모형이다. 일반적으로 학습에서 최적화 목적함수로 사용된다.\n",
    "# 정밀도(precision)은 양성 클래스에 속한다고 출력한 샘플 중 실제로 양성 클래스에 속하는 샘플 수의 비율을 말한다. 높을수록 좋은 모형이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804416df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67da123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  0,  0,  3,  0,  0,  0, -2,  0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "predict = np.array([1, 1, 3, 4, 8, 6, 7, 8, 7, 10])\n",
    "predict - y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b42a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_test, predict):\n",
    "    return abs(y_test - predict).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e384c114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "print(mae(y_test, predict))\n",
    "print(mean_absolute_error(y_test, predict))\n",
    "# -1, 3, -2를 절대값으로 바꾸고 평균을 냈구나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84999e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_test, predict):\n",
    "    return ((y_test - predict)**2).mean()\n",
    "# (y_test - predict)의 제곱한걸로 평균 .mean() 을 내겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24b1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "455f7099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test, predict)\n",
    "mean_squared_error(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b584b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, predict):\n",
    "    return np.sqrt(((y_test - predict)**2).mean())\n",
    "# 아까거 가져와서 전체에 루트 씌운다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4e07ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1832159566199232"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1832159566199232"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_test, predict)\n",
    "mean_squared_error(y_test, predict, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c6d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_r2_score(y_test, predict):\n",
    "    y_bar = y_test.mean()\n",
    "    ss_tot = ((y_test - y_bar)**2).sum()\n",
    "    ss_res = ((y_test - predict)**2).sum()\n",
    "    \n",
    "    return 1 - (ss_res / ss_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c9d085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303030303030303"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8303030303030303"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_r2_score(y_test, predict)\n",
    "r2_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e36e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  검사하지 않는 숙제 맨윗줄 이해하고 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba5dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
